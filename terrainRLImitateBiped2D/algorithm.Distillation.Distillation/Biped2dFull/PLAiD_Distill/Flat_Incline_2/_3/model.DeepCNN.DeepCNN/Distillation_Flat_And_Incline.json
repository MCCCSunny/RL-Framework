{
    "comment__": "This overrides all of the envs to be a single one from the list of sim environments",
    "model_type": "model.DeepCNN.DeepCNN",
    "agent_name": "algorithm.Distillation.Distillation",
    "data_folder": "Biped2dFull/PLAiD_Distill/Flat_Incline_2/_3",
    "comment": "initial probability of selecting a discrete random action",
    "epsilon": 1.0,
    "omega": 0.0,
    "batch_size": 32,
    "learning_rate": 0.0001,
    "sim_config_file": [
        "./args/genBiped2D/biped2dfull_flat_with_terrain_features.txt",
        "./args/genBiped2D/biped2dfull_incline_with_terrain_features.txt"
    ],
    "forwardDynamics_config_file": [
        "./args/genBiped2D/biped2dfull_flat_with_terrain_features.txt",
        "./args/genBiped2D/biped2dfull_incline_with_terrain_features.txt"
    ],
    "anchor_file": "../data/anchorData/paperGibbonAnchors.json",
    "exploration_rate": 0.0001,
    "rounds": 100,
    "epochs": 10,
    "eval_epochs": 10,
    "discount_factor": 0.95,
    "visualize_learning": false,
    "save_trainData": true,
    "train_forward_dynamics": false,
    "reward_bounds": [
        [
            0.0
        ],
        [
            1.0
        ]
    ],
    "expereince_length": 20000,
    "state_bounds": [
        [
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            -1.0,
            0.06586086,
            -0.33134258,
            -0.22473772,
            -0.08842427,
            -0.24940665,
            -0.15451589,
            -0.49955064,
            -0.44008026,
            -0.59096092,
            -0.27878672,
            -0.14038287,
            -0.28852576,
            -0.20101279,
            -0.22234532,
            -0.22769515,
            -0.54376805,
            -0.35379013,
            -0.3725186,
            -0.33276483,
            -0.67418987,
            -0.35524186,
            -0.45274141,
            -0.25600547,
            -0.86293733,
            -0.60379982,
            -1.3963486,
            -1.35225046,
            -1.56099963,
            -1.59434652,
            -2.93630743,
            -3.02572751,
            -4.52309895,
            -5.14550066,
            -1.79466832,
            -1.95292163,
            -2.29718137,
            -2.53373265,
            -2.79888201,
            -3.67393041,
            -1.96048367,
            -2.22237873,
            -4.52637959,
            -5.36702728,
            -1.79870808,
            -1.6695528,
            -2.83235455,
            -2.84780359,
            -1.73784041,
            -2.26103067,
            -0.062334,
            -0.61482263,
            -0.61719877,
            -0.61664611,
            -0.61482263
        ],
        [
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            1.0,
            0.61076754,
            0.30874607,
            0.16389988,
            0.278528,
            0.10735691,
            0.55370122,
            0.28979328,
            0.88343042,
            0.46615249,
            0.24841864,
            0.25305298,
            0.20827545,
            0.35527417,
            0.10670558,
            0.34333566,
            0.46612564,
            0.34286582,
            0.24609406,
            0.55321878,
            0.50907576,
            0.41017145,
            0.19810088,
            0.49811089,
            0.83155686,
            0.40484139,
            1.4751488,
            1.06637669,
            1.60812414,
            1.50176299,
            3.01205444,
            3.09199214,
            4.45173025,
            5.29966736,
            1.6375221,
            1.83521891,
            2.14798474,
            2.5548656,
            2.72522235,
            3.7703712,
            2.17525077,
            1.90829098,
            4.67793322,
            5.20727777,
            1.98003554,
            1.36583793,
            2.76746488,
            2.68556261,
            2.02427745,
            1.82794178,
            1.07712889,
            1.10115075,
            1.13575351,
            1.12543523,
            1.10115075
        ]
    ],
    "action_bounds": [
        [
            -2.57,
            -3.14,
            -1.57,
            -2.57,
            -3.14,
            -1.57,
            -1.2,
            0.0,
            -1.2,
            0.0,
            -0.57
        ],
        [
            2.57,
            0.5,
            1.57,
            2.57,
            0.5,
            1.57,
            3.0,
            2.8,
            3.0,
            2.8,
            0.57
        ]
    ],
    "discrete_actions": [
        [
            -0.1,
            -2.3,
            0.15,
            -1.35,
            -3.0,
            1.2
        ],
        [
            -2.2,
            -0.74,
            1.25,
            -0.11,
            -1.3,
            0.7
        ],
        [
            -0.1,
            -0.4,
            0.35,
            -1.44,
            0.3,
            -1.1
        ],
        [
            1.1,
            -2.45,
            0.45,
            -0.53,
            -1.43,
            0.7
        ],
        [
            -0.1,
            -0.55,
            0.35,
            1.23,
            0.3,
            1.17
        ],
        [
            0.14,
            -0.45,
            -0.45,
            -0.15,
            -1.53,
            1.27
        ],
        [
            1.1,
            -3.1,
            0.55,
            -0.12,
            0.3,
            -0.7
        ],
        [
            -1.1,
            -0.65,
            -0.35,
            -0.67,
            -2.3,
            0.7
        ],
        [
            -0.1,
            0.25,
            0.3,
            1.71,
            0.3,
            1.17
        ]
    ],
    "action_space_continuous": true,
    "train_on_validation_set": true,
    "environment_type": "terrainRLImitateBiped2D",
    "forward_dynamics_predictor": "simulator",
    "sampling_method": "SequentialMC",
    "use_actor_policy_action_suggestion": true,
    "num_uniform_action_samples": 2,
    "look_ahead_planning_steps": 2,
    "plotting_update_freq_num_rounds": 10,
    "saving_update_freq_num_rounds": 100,
    "num_available_threads": 2,
    "queue_size_limit": 500,
    "sim_action_per_training_update": 8,
    "adaptive_samples": 25,
    "num_adaptive_samples_to_keep": 50,
    "use_actor_policy_action_variance_suggestion": false,
    "exploration_method": "gaussian_random",
    "dropout_p": 0.1,
    "regularization_weight": 1e-05,
    "rho": 0.95,
    "rms_epsilon": 1e-06,
    "steps_until_target_network_update": 100,
    "epsilon_annealing": 0.8,
    "state_normalization": "given",
    "load_saved_model": "network_and_scales",
    "critic_updates_per_actor_update": 1,
    "clamp_actions_to_stay_inside_bounds": true,
    "bootstrap_samples": 128,
    "bootsrap_with_discrete_policy": true,
    "max_epoch_length": 256,
    "reward_lower_bound": -5.0,
    "training_updates_per_sim_action": 1,
    "use_model_based_action_optimization": false,
    "use_transfer_task_network": false,
    "penalize_actions_outside_bounds": false,
    "forward_dynamics_model_type": "model.ForwardDynamicsDenseNetworkDropout.ForwardDynamicsDenseNetworkDropout",
    "save_experience_memory": false,
    "train_rl_learning": true,
    "use_back_on_track_forcing": false,
    "visualize_forward_dynamics": false,
    "fd_learning_rate": 0.001,
    "train_actor": true,
    "debug_critic": true,
    "critic_regularization_weight": 1e-05,
    "critic_learning_rate": 0.001,
    "visualize_expected_value": true,
    "target_velocity_decay": -2.0,
    "target_velocity": 1.0,
    "num_terrain_features": 50,
    "initial_temperature": 2.0,
    "min_epsilon": 0.2,
    "shouldRender": false,
    "action_learning_rate": 1.0,
    "model_based_action_omega": 0.5,
    "debug_actor": true,
    "float_type": "float32",
    "training_processor_type": "cpu",
    "optimizer": "adam",
    "use_simulation_sampling": false,
    "variance_scalling": 0.05,
    "use_parameterized_control": false,
    "controller_parameter_settings": {
        "velocity_bounds": [
            [
                0.5
            ],
            [
                2.5
            ]
        ]
    },
    "average_parameter_change": 0.25,
    "train_critic_on_fd_output": false,
    "use_previous_value_regularization": false,
    "print_level": "hyper_train",
    "print_levels": {
        "debug": 1,
        "train": 0,
        "hyper_train": -1
    },
    "reward_smoother": "gaussian",
    "controller_reward_weights": {
        "velocity": 0.8,
        "torque": 0.05,
        "root_height": 0.05,
        "root_pitch": 0.1,
        "right_hand_x_pos": 0.0
    },
    "previous_value_regularization_weight": 0.001,
    "random_seed": 1252,
    "on_policy": false,
    "use_stocastic_policy": false,
    "train_critic": true,
    "regularization_type": "kl",
    "collect_tuples_in_batches": false,
    "reset_on_fall": true,
    "motion_file": "../data/mocap/walk/two_steps.json",
    "train_reward_predictor": false,
    "num_mbae_steps": 1,
    "fix_actor_batch_size": true,
    "anneal_mbae": false,
    "dyna_update_lag_steps": 2,
    "use_random_actions_for_MBAE": false,
    "only_use_exp_actions_for_poli_updates": true,
    "randomize_MBAE_action_length": true,
    "use_GAE": true,
    "GAE_lambda": 0.95,
    "use_multiple_policy_updates": false,
    "clear_exp_mem_on_poli": false,
    "use_fixed_std": false,
    "disable_parameter_scaling": false,
    "train_state_encoding": false,
    "std_entropy_weight": 0.01,
    "policy_loss_weight": 1.0,
    "num_on_policy_rollouts": 1,
    "dont_use_advantage": true,
    "load_saved_fd_model": false,
    "annealing_schedule": "log",
    "expert_policy_files": [
        "terrainRLImitateBiped2D/algorithm.A_CACLA.A_CACLA/Biped2dFull/MultiTasker/_Flat_Incline/_3",
        "terrainRLImitateBiped2D/algorithm.A_CACLA.A_CACLA/Biped2dFull/TL_Only/Steps_TL_From_Incline/_3"
    ],
    "run_distillation_in_test_mode": false,
    "override_sim_env_id": 1
}